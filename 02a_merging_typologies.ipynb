{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "base", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.13.9"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md_title",
   "metadata": {},
   "source": [
    "# ğŸ’³ SmartSentry AML â€” Notebook 2a: Merging & Typologies\n",
    "---\n",
    "Generates legitimate and fraud transactions across **11 typologies** (8 original + 3 new inactive-user reactivation patterns), merges and rebalances to the target fraud rate, then enriches with entity FK-joins, IP-graph features, and shared-identity markers.\n",
    "\n",
    "## âœ¨ Inactive-User Feature â€” Design Summary\n",
    "\n",
    "| Item | Detail |\n",
    "|---|---|\n",
    "| **Pool size** | 5% of all accounts (`INACTIVE_ACCOUNT_FRAC = 0.05`) |\n",
    "| **No-overlap guarantee** | `inactive_account_set âˆ© dormant_account_set = âˆ…` enforced at sampling |\n",
    "| **Definition of inactive** | No transactions for â‰¥ 45 days (`INACTIVE_GAP_DAYS`) before reactivation |\n",
    "| **Account lifecycle** | Early cluster (days 0â€“EARLY_END) â†’ silence (â‰¥45 days) â†’ reactivation burst |\n",
    "| **`no_of_inactive_days`** | New integer column on **every** row. `NaN` for non-inactive accounts; `0` for pre-silence early rows; actual gap days (â‰¥45) for reactivation rows |\n",
    "| **Fraud sub-patterns** | `inactive_ATO` (35%), `inactive_smurfing` (20%), `inactive_to_offshore` (20%) |\n",
    "| **Clean reactivation** | 25% of inactive accounts reactivate legitimately â€” `label=0` but still carry `no_of_inactive_days` |\n",
    "| **IP signal** | `inactive_ATO` rows always assigned `ip_type='risk'` (adversary control) |\n",
    "| **Shared identity** | Each inactive sub-pattern gets distinct KYC / phone / email group IDs |\n",
    "\n",
    "**Inputs :** `outputs/customers.csv`, `accounts.csv`, `devices.csv`, `beneficiaries.csv`\n",
    "\n",
    "**Outputs :**\n",
    "- `outputs/txns_stage1.parquet` â€” full enriched transaction table  \n",
    "- `outputs/dormant_account_set.csv` â€” dormant account IDs (for Notebook 2b)  \n",
    "- `outputs/inactive_account_set.csv` â€” inactive account IDs + last active timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "A1_imports",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# â”€â”€ A-1: Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import random\n",
    "import warnings\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "OUTPUT_DIR = Path('./outputs')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print('âœ… Libraries loaded')"
   ]
  },
  {
   "cell_type": "code",
   "id": "A2_config",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# â”€â”€ A-2: Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "START_DATE      = datetime(2025, 9, 1)\n",
    "END_DATE        = datetime(2025, 12, 31)\n",
    "DATE_RANGE_DAYS = (END_DATE - START_DATE).days\n",
    "\n",
    "TARGET_FRAUD_RATE            = 0.04\n",
    "AVG_TXNS_PER_ACCOUNT_PER_DAY = 50 / DATE_RANGE_DAYS\n",
    "AVG_TXNS_PER_ACCOUNT         = AVG_TXNS_PER_ACCOUNT_PER_DAY * DATE_RANGE_DAYS\n",
    "\n",
    "# â”€â”€ Dormant account config (UNCHANGED) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DORMANT_ACCOUNT_FRAC  = 0.05\n",
    "_dorm_split_end       = max(25, int(DATE_RANGE_DAYS * 0.20))\n",
    "_dorm_second_start    = max(_dorm_split_end + 35, int(DATE_RANGE_DAYS * 0.55))\n",
    "DORMANT_FIRST_WINDOW  = (0, _dorm_split_end)\n",
    "DORMANT_SECOND_WINDOW = (_dorm_second_start, DATE_RANGE_DAYS)\n",
    "DORMANT_FIRST_TXNS    = (3, 8)\n",
    "DORMANT_SECOND_TXNS   = (5, 15)\n",
    "\n",
    "# â”€â”€ Inactive account config (NEW) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#\n",
    "# Lifecycle:\n",
    "#   Phase 1 (active)  : days 0 .. INACTIVE_EARLY_END    â†’ small legit cluster\n",
    "#   Phase 2 (silent)  : INACTIVE_EARLY_END .. INACTIVE_REACT_START (â‰¥ 45 days)\n",
    "#   Phase 3 (reactiv.): INACTIVE_REACT_START .. DATE_RANGE_DAYS  â†’ risky or clean\n",
    "#\n",
    "INACTIVE_ACCOUNT_FRAC  = 0.05          # 5 % of all accounts\n",
    "INACTIVE_GAP_DAYS      = 45            # minimum silence before reactivation\n",
    "INACTIVE_EARLY_END     = max(20, int(DATE_RANGE_DAYS * 0.15))        # e.g. day 18\n",
    "INACTIVE_REACT_START   = INACTIVE_EARLY_END + INACTIVE_GAP_DAYS      # e.g. day 63\n",
    "INACTIVE_EARLY_TXNS    = (2, 6)        # transactions before going silent\n",
    "\n",
    "# Sub-pattern allocation â€” MUST sum to exactly 1.0\n",
    "# These are mutually exclusive slices of inactive_account_set\n",
    "INACTIVE_FRAUD_FRACS = {\n",
    "    'inactive_ATO'         : 0.35,   # foreign device + large off-hours transfer\n",
    "    'inactive_smurfing'    : 0.20,   # cash structuring burst just below threshold\n",
    "    'inactive_to_offshore' : 0.20,   # wire to crypto / offshore after silence\n",
    "    'inactive_legit'       : 0.25,   # clean reactivation (label=0)\n",
    "}\n",
    "assert abs(sum(INACTIVE_FRAUD_FRACS.values()) - 1.0) < 1e-9, 'Fracs must sum to 1.0'\n",
    "\n",
    "# â”€â”€ Channel / TXN config (UNCHANGED) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CHANNELS      = ['mobile', 'web', 'branch', 'atm']\n",
    "CHANNEL_PROBS = [0.50, 0.30, 0.10, 0.10]\n",
    "TXN_TYPES_BY_CHANNEL = {\n",
    "    'mobile': ['UPI', 'IMPS', 'wallet_transfer'],\n",
    "    'web':    ['NEFT', 'RTGS', 'online_transfer'],\n",
    "    'branch': ['cash_deposit', 'cash_withdrawal', 'DD'],\n",
    "    'atm':    ['cash_withdrawal', 'balance_enquiry'],\n",
    "}\n",
    "CASH_TXN_TYPES = {'cash_deposit', 'cash_withdrawal', 'DD'}\n",
    "\n",
    "AMOUNT_BY_KYC = {\n",
    "    'low':    {'mean': 7.0, 'sigma': 1.0},\n",
    "    'medium': {'mean': 8.0, 'sigma': 1.0},\n",
    "    'high':   {'mean': 9.5, 'sigma': 1.0},\n",
    "}\n",
    "AMOUNT_DEFAULT         = {'mean': 8.0, 'sigma': 1.0}\n",
    "INTERNAL_TRANSFER_PROB = 0.40\n",
    "\n",
    "HOUR_WEIGHTS_NORMAL = [1,1,1,1,1,1,2,3,5,6,6,6,5,6,6,6,5,5,4,4,3,2,2,1]\n",
    "HOUR_WEIGHTS_FRAUD  = [4,4,4,4,3,2,1,1,1,1,1,1,1,1,1,1,2,2,3,3,4,4,4,4]\n",
    "\n",
    "_scale = DATE_RANGE_DAYS / 121\n",
    "FRAUD_VOLUMES = {\n",
    "    # â”€â”€ Original 8 active / dormant typologies (UNCHANGED) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    'mule_ring'           : {'num_rings'          : max(1,int(60*_scale)),\n",
    "                             'accounts_per_ring'  : 10,\n",
    "                             'txns_per_account'   : 8,\n",
    "                             'day_min'            : int(DATE_RANGE_DAYS*0.50),\n",
    "                             'day_max'            : int(DATE_RANGE_DAYS*0.99),\n",
    "                             'amount_mean'        : 9.5,\n",
    "                             'amount_sigma'       : 0.5,\n",
    "                             'channels'           : ['mobile','web']},\n",
    "    'layering'            : {'num_chains'         : max(1,int(900*_scale)),\n",
    "                             'chain_length'       : 3,\n",
    "                             'day_min'            : int(DATE_RANGE_DAYS*0.60),\n",
    "                             'day_max'            : int(DATE_RANGE_DAYS*0.99),\n",
    "                             'hop_min_mins'       : 5,\n",
    "                             'hop_max_mins'       : 30,\n",
    "                             'amount_mean_base'   : 9.0,\n",
    "                             'amount_mean_decay'  : 0.2,\n",
    "                             'amount_sigma'       : 0.8,\n",
    "                             'channels'           : ['mobile','web']},\n",
    "    'ATO'                 : {'count'              : max(1,int(2000*_scale)),\n",
    "                             'day_min'            : int(DATE_RANGE_DAYS*0.70),\n",
    "                             'day_max'            : int(DATE_RANGE_DAYS*0.99),\n",
    "                             'amount_mean'        : 10.5,\n",
    "                             'amount_sigma'       : 0.8,\n",
    "                             'channels'           : ['mobile','web']},\n",
    "    'smurfing'            : {'num_groups'         : max(1,int(400*_scale)),\n",
    "                             'min_txns'           : 4,\n",
    "                             'max_txns'           : 8,\n",
    "                             'amount_min'         : 8500,\n",
    "                             'amount_max'         : 9999,\n",
    "                             'day_window'         : 2,\n",
    "                             'channels'           : ['branch','atm'],\n",
    "                             'force_cash_flag'    : True},\n",
    "    'identity_fraud'      : {'count'              : max(1,int(800*_scale)),\n",
    "                             'max_account_days'   : 60,\n",
    "                             'day_min'            : 0,\n",
    "                             'day_max'            : int(DATE_RANGE_DAYS*0.25),\n",
    "                             'amount_mean'        : 11.0,\n",
    "                             'amount_sigma'       : 0.6,\n",
    "                             'channels'           : ['mobile','web']},\n",
    "    'dormant_ATO'         : {'frac_dormant_targeted': 0.60,\n",
    "                             'txns_per_account'   : (2,5),\n",
    "                             'amount_mean'        : 11.0,\n",
    "                             'amount_sigma'       : 0.7,\n",
    "                             'channels'           : ['mobile','web']},\n",
    "    'dormant_smurfing'    : {'frac_dormant_targeted': 0.25,\n",
    "                             'min_txns'           : 3,\n",
    "                             'max_txns'           : 6,\n",
    "                             'amount_min'         : 8500,\n",
    "                             'amount_max'         : 9999,\n",
    "                             'channels'           : ['branch','atm'],\n",
    "                             'force_cash_flag'    : True,\n",
    "                             'day_window'         : 3},\n",
    "    'dormant_to_offshore' : {'frac_dormant_targeted': 0.30,\n",
    "                             'txns_per_account'   : (1,3),\n",
    "                             'amount_mean'        : 11.5,\n",
    "                             'amount_sigma'       : 0.5,\n",
    "                             'channels'           : ['web','mobile']},\n",
    "    # â”€â”€ NEW: 3 inactive-user fraud typologies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Applied ONLY to inactive_account_set; zero overlap with dormant / active.\n",
    "    'inactive_ATO'        : {'txns_per_account'   : (3, 7),\n",
    "                             'amount_mean'        : 11.2,\n",
    "                             'amount_sigma'       : 0.9,\n",
    "                             'channels'           : ['mobile','web'],\n",
    "                             'new_device'         : True},   # foreign device flag\n",
    "    'inactive_smurfing'   : {'min_txns'           : 3,\n",
    "                             'max_txns'           : 7,\n",
    "                             'amount_min'         : 8000,\n",
    "                             'amount_max'         : 9999,\n",
    "                             'channels'           : ['branch','atm'],\n",
    "                             'force_cash_flag'    : True,\n",
    "                             'day_window'         : 3},\n",
    "    'inactive_to_offshore': {'txns_per_account'   : (1, 4),\n",
    "                             'amount_mean'        : 12.0,\n",
    "                             'amount_sigma'       : 0.5,\n",
    "                             'channels'           : ['web','mobile']},\n",
    "}\n",
    "\n",
    "IP_HOME_FRAC          = 0.70\n",
    "IP_ROAM_FRAC          = 0.20\n",
    "IP_HOME_BASE_SCORE    = 0.05\n",
    "IP_ROAM_BASE_SCORE    = 0.30\n",
    "IP_RISK_BASE_SCORE    = 0.80\n",
    "HIGH_RISK_IP_PREFIXES = ['185.220','45.142','198.96','176.10','162.247',\n",
    "                         '91.108','77.247','104.244','194.165','185.107']\n",
    "\n",
    "print('âœ… Configuration loaded')\n",
    "print(f'   Date range           : {START_DATE.date()} â†’ {END_DATE.date()} ({DATE_RANGE_DAYS} days)')\n",
    "print(f'   Fraud target         : {TARGET_FRAUD_RATE:.0%}')\n",
    "print(f'   Dormant accounts     : {DORMANT_ACCOUNT_FRAC:.0%}')\n",
    "print(f'   Inactive accounts    : {INACTIVE_ACCOUNT_FRAC:.0%}  (gap â‰¥ {INACTIVE_GAP_DAYS} days)')\n",
    "print(f'   Inactive early end   : day {INACTIVE_EARLY_END}')\n",
    "print(f'   Inactive react start : day {INACTIVE_REACT_START}')\n",
    "print(f'   Dormant window 1     : days {DORMANT_FIRST_WINDOW[0]}â€“{DORMANT_FIRST_WINDOW[1]}')\n",
    "print(f'   Dormant window 2     : days {DORMANT_SECOND_WINDOW[0]}â€“{DORMANT_SECOND_WINDOW[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "id": "A3_load",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# â”€â”€ A-3: Load Reference Tables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "customers     = pd.read_csv(OUTPUT_DIR / 'customers.csv')\n",
    "accounts      = pd.read_csv(OUTPUT_DIR / 'accounts.csv')\n",
    "devices       = pd.read_csv(OUTPUT_DIR / 'devices.csv')\n",
    "beneficiaries = pd.read_csv(OUTPUT_DIR / 'beneficiaries.csv')\n",
    "\n",
    "device_list        = devices['device_id'].tolist()\n",
    "account_device_map = {acc: random.choice(device_list) for acc in accounts['account_id']}\n",
    "\n",
    "bene_list = beneficiaries['beneficiary_id'].tolist()\n",
    "account_beneficiaries_map = {\n",
    "    acc: random.sample(bene_list, k=random.randint(2, 5))\n",
    "    for acc in accounts['account_id']\n",
    "}\n",
    "\n",
    "high_risk_mask = (\n",
    "    beneficiaries['beneficiary_type'].isin({'crypto', 'offshore'}) |\n",
    "    (beneficiaries['beneficiary_country_risk'] == 'high')\n",
    ")\n",
    "high_risk_bene_pool  = beneficiaries.loc[high_risk_mask, 'beneficiary_id'].tolist()\n",
    "offshore_crypto_pool = beneficiaries.loc[\n",
    "    beneficiaries['beneficiary_type'].isin({'crypto', 'offshore'}),\n",
    "    'beneficiary_id'\n",
    "].tolist()\n",
    "\n",
    "all_account_ids = accounts['account_id'].tolist()\n",
    "\n",
    "# â”€â”€ Dormant account set (original logic) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "n_dormant           = max(1, int(len(all_account_ids) * DORMANT_ACCOUNT_FRAC))\n",
    "dormant_account_set = set(random.sample(all_account_ids, n_dormant))\n",
    "\n",
    "# â”€â”€ Inactive account set â€” sampled from NON-dormant accounts only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "eligible_for_inactive = [a for a in all_account_ids if a not in dormant_account_set]\n",
    "n_inactive            = max(1, int(len(all_account_ids) * INACTIVE_ACCOUNT_FRAC))\n",
    "inactive_account_set  = set(random.sample(eligible_for_inactive, n_inactive))\n",
    "\n",
    "# Hard guarantee: zero overlap\n",
    "assert dormant_account_set.isdisjoint(inactive_account_set), \\\n",
    "    'âŒ dormant âˆ© inactive overlap detected'\n",
    "\n",
    "if 'home_lat' in accounts.columns:\n",
    "    cust_geo_map = (\n",
    "        accounts[['customer_id','home_lat','home_lon']]\n",
    "        .drop_duplicates('customer_id')\n",
    "        .set_index('customer_id')\n",
    "    )\n",
    "else:\n",
    "    cust_geo_map = None\n",
    "\n",
    "acc_open_date_map = {\n",
    "    row['account_id']: START_DATE.date() - timedelta(days=int(row['account_open_days']))\n",
    "    for _, row in accounts.iterrows()\n",
    "}\n",
    "\n",
    "print('âœ… Reference tables loaded')\n",
    "print(f'   customers: {len(customers):,} | accounts: {len(accounts):,} | '\n",
    "      f'devices: {len(devices):,} | beneficiaries: {len(beneficiaries):,}')\n",
    "print(f'   high_risk_bene_pool  : {len(high_risk_bene_pool):,}')\n",
    "print(f'   dormant_account_set  : {len(dormant_account_set):,} '\n",
    "      f'({len(dormant_account_set)/len(all_account_ids):.1%} of accounts)')\n",
    "print(f'   inactive_account_set : {len(inactive_account_set):,} '\n",
    "      f'({len(inactive_account_set)/len(all_account_ids):.1%} of accounts)')\n",
    "print(f'   Overlap check        : âœ… dormant âˆ© inactive = 0')"
   ]
  },
  {
   "cell_type": "code",
   "id": "A4_builder",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# â”€â”€ A-4: Shared Transaction Builder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def weighted_hour(fraud=False):\n",
    "    weights = HOUR_WEIGHTS_FRAUD if fraud else HOUR_WEIGHTS_NORMAL\n",
    "    return random.choices(range(24), weights=weights)[0]\n",
    "\n",
    "def random_ts(fraud=False, day_min=0, day_max=None):\n",
    "    \"\"\"Return a random datetime within the simulation window.\"\"\"\n",
    "    if day_max is None:\n",
    "        day_max = DATE_RANGE_DAYS\n",
    "    day_max = min(day_max, DATE_RANGE_DAYS)\n",
    "    return START_DATE + timedelta(\n",
    "        days    = random.randint(day_min, day_max),\n",
    "        hours   = weighted_hour(fraud),\n",
    "        minutes = random.randint(0, 59),\n",
    "        seconds = random.randint(0, 59),\n",
    "    )\n",
    "\n",
    "def get_txn_type(channel):\n",
    "    return random.choice(TXN_TYPES_BY_CHANNEL.get(channel, ['online_transfer']))\n",
    "\n",
    "def is_cash(txn_type):\n",
    "    return int(txn_type in CASH_TXN_TYPES)\n",
    "\n",
    "TXN_COLS = [\n",
    "    'transaction_id', 'customer_id', 'sender_account_id', 'receiver_account_id',\n",
    "    'beneficiary_id', 'device_id', 'timestamp', 'amount', 'channel', 'debit_credit',\n",
    "    'transaction_type', 'cash_flag', 'synthetic_flow_id', 'flow_depth', 'hop_number',\n",
    "    'time_since_origin_ts', 'fraud_type', 'label',\n",
    "]\n",
    "_FRAUD_TYPE_IDX    = TXN_COLS.index('fraud_type')\n",
    "_CASH_FLAG_IDX     = TXN_COLS.index('cash_flag')\n",
    "_SENDER_ACCT_IDX   = TXN_COLS.index('sender_account_id')\n",
    "\n",
    "def build_row(txn_id, customer_id, sender_account_id, device_id,\n",
    "              ts, amount, channel, fraud_type, label,\n",
    "              receiver_account_id=None, beneficiary_id=None,\n",
    "              synthetic_flow_id=None, flow_depth=None,\n",
    "              hop_number=None, time_since_origin_ts=None,\n",
    "              force_cash=False):\n",
    "    txn_type = get_txn_type(channel)\n",
    "    cash     = 1 if force_cash else is_cash(txn_type)\n",
    "    return [\n",
    "        f'T{txn_id}', customer_id, sender_account_id, receiver_account_id,\n",
    "        beneficiary_id, device_id, ts, round(amount, 2), channel, 'debit',\n",
    "        txn_type, cash, synthetic_flow_id, flow_depth, hop_number,\n",
    "        time_since_origin_ts, fraud_type, label,\n",
    "    ]\n",
    "\n",
    "print(f'âœ… Transaction builder ready  ({len(TXN_COLS)} columns)')"
   ]
  },
  {
   "cell_type": "code",
   "id": "A5_legit",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# â”€â”€ A-5: Generate Legitimate Transactions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#\n",
    "# Three account populations:\n",
    "#   (a) Normal active   â†’ full Poisson-distributed history\n",
    "#   (b) Dormant         â†’ early cluster + late cluster  (original logic)\n",
    "#   (c) Inactive        â†’ EARLY CLUSTER ONLY here (pre-silence phase)\n",
    "#                         Reactivation rows injected in Cell A-7.\n",
    "\n",
    "acc_meta    = accounts.set_index('account_id')\n",
    "legit_rows  = []\n",
    "txn_id      = 0\n",
    "\n",
    "def _legit_row(acc, cust, device, kyc, day_min, day_max, txn_id):\n",
    "    params = AMOUNT_BY_KYC.get(str(kyc).lower(), AMOUNT_DEFAULT)\n",
    "    ts     = random_ts(fraud=False, day_min=day_min, day_max=day_max)\n",
    "    amount = np.random.lognormal(mean=params['mean'], sigma=params['sigma'])\n",
    "    ch     = random.choices(CHANNELS, weights=CHANNEL_PROBS)[0]\n",
    "    if random.random() < INTERNAL_TRANSFER_PROB:\n",
    "        return build_row(txn_id, cust, acc, device, ts, amount, ch, 'normal', 0,\n",
    "                         receiver_account_id=random.choice(all_account_ids))\n",
    "    else:\n",
    "        return build_row(txn_id, cust, acc, device, ts, amount, ch, 'normal', 0,\n",
    "                         beneficiary_id=random.choice(account_beneficiaries_map[acc]))\n",
    "\n",
    "dormant_count_total  = 0\n",
    "inactive_early_count = 0\n",
    "\n",
    "for acc in accounts['account_id']:\n",
    "    kyc    = acc_meta.loc[acc, 'kyc_level']\n",
    "    cust   = acc_meta.loc[acc, 'customer_id']\n",
    "    device = account_device_map[acc]\n",
    "\n",
    "    if acc in dormant_account_set:\n",
    "        # â”€â”€ Dormant: two clusters separated by long silence (original) â”€â”€â”€â”€\n",
    "        n_first  = random.randint(*DORMANT_FIRST_TXNS)\n",
    "        n_second = random.randint(*DORMANT_SECOND_TXNS)\n",
    "        for _ in range(n_first):\n",
    "            legit_rows.append(_legit_row(acc, cust, device, kyc,\n",
    "                                         DORMANT_FIRST_WINDOW[0],\n",
    "                                         DORMANT_FIRST_WINDOW[1], txn_id))\n",
    "            txn_id += 1\n",
    "        for _ in range(n_second):\n",
    "            legit_rows.append(_legit_row(acc, cust, device, kyc,\n",
    "                                         DORMANT_SECOND_WINDOW[0],\n",
    "                                         DORMANT_SECOND_WINDOW[1], txn_id))\n",
    "            txn_id += 1\n",
    "        dormant_count_total += n_first + n_second\n",
    "\n",
    "    elif acc in inactive_account_set:\n",
    "        # â”€â”€ Inactive: ONLY pre-silence early cluster here â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        n_early = random.randint(*INACTIVE_EARLY_TXNS)\n",
    "        for _ in range(n_early):\n",
    "            legit_rows.append(_legit_row(acc, cust, device, kyc,\n",
    "                                         0, INACTIVE_EARLY_END, txn_id))\n",
    "            txn_id += 1\n",
    "        inactive_early_count += n_early\n",
    "\n",
    "    else:\n",
    "        # â”€â”€ Normal active account â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        n_txns = np.random.poisson(AVG_TXNS_PER_ACCOUNT)\n",
    "        for _ in range(n_txns):\n",
    "            legit_rows.append(_legit_row(acc, cust, device, kyc,\n",
    "                                         0, DATE_RANGE_DAYS, txn_id))\n",
    "            txn_id += 1\n",
    "\n",
    "legit_df  = pd.DataFrame(legit_rows, columns=TXN_COLS)\n",
    "n_active  = len(all_account_ids) - len(dormant_account_set) - len(inactive_account_set)\n",
    "\n",
    "print(f'âœ… Legitimate transactions : {len(legit_df):,} rows')\n",
    "print(f'   Active accounts          : {n_active:,}')\n",
    "print(f'   Dormant accounts         : {len(dormant_account_set):,}  ({dormant_count_total:,} rows)')\n",
    "print(f'   Inactive accts (early Î¦1): {len(inactive_account_set):,}  ({inactive_early_count:,} rows â€” pre-silence only)')\n",
    "print(f'   Internal transfers       : {legit_df[\"receiver_account_id\"].notna().sum():,}')\n",
    "print(f'   External transfers       : {legit_df[\"beneficiary_id\"].notna().sum():,}')\n",
    "legit_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "id": "A6_fraud_active",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# â”€â”€ A-6: Inject Fraud Typologies (Original 8 â€” Active & Dormant only) â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#\n",
    "# Sampling pool explicitly EXCLUDES inactive_account_set.\n",
    "# This guarantees the 8 original typologies never touch inactive accounts.\n",
    "\n",
    "acc_meta_fraud  = accounts.set_index('account_id')\n",
    "active_pool     = [a for a in accounts['account_id'].tolist()\n",
    "                   if a not in inactive_account_set]       # dormant still included\n",
    "all_devs        = devices['device_id'].tolist()\n",
    "fraud_rows      = []\n",
    "\n",
    "# â”€â”€ 6A: MULE RINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cfg = FRAUD_VOLUMES['mule_ring']\n",
    "_mule_flow_counter = 0\n",
    "for _ in range(cfg['num_rings']):\n",
    "    mule_accs      = random.sample(active_pool, cfg['accounts_per_ring'])\n",
    "    shared_dev     = random.choice(all_devs)\n",
    "    exit_bene      = random.choice(high_risk_bene_pool)\n",
    "    flow_id        = f'FLOW_{_mule_flow_counter:05d}'\n",
    "    ring_depth     = len(mule_accs)\n",
    "    ring_origin_ts = random_ts(True, cfg['day_min'], cfg['day_max'])\n",
    "    _mule_flow_counter += 1\n",
    "    for hop_i, acc in enumerate(mule_accs, start=1):\n",
    "        cust = acc_meta_fraud.loc[acc, 'customer_id']\n",
    "        for _ in range(cfg['txns_per_account']):\n",
    "            ts  = random_ts(True, cfg['day_min'], cfg['day_max'])\n",
    "            amt = np.random.lognormal(cfg['amount_mean'], cfg['amount_sigma'])\n",
    "            ch  = random.choice(cfg['channels'])\n",
    "            fraud_rows.append(build_row(\n",
    "                txn_id, cust, acc, shared_dev, ts, amt, ch, 'mule_ring', 1,\n",
    "                beneficiary_id=exit_bene,\n",
    "                synthetic_flow_id=flow_id, flow_depth=ring_depth,\n",
    "                hop_number=hop_i, time_since_origin_ts=ring_origin_ts,\n",
    "            ))\n",
    "            txn_id += 1\n",
    "\n",
    "_mr_count = sum(1 for r in fraud_rows if r[_FRAUD_TYPE_IDX] == 'mule_ring')\n",
    "print(f'  Mule rings          : {_mr_count:>6,} rows')\n",
    "\n",
    "# â”€â”€ 6B: LAYERING CHAINS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cfg = FRAUD_VOLUMES['layering']\n",
    "_layer_flow_counter = 10_000\n",
    "for _ in range(cfg['num_chains']):\n",
    "    chain       = random.sample(active_pool, cfg['chain_length']) + [None]\n",
    "    chain[-1]   = chain[0]\n",
    "    base_ts     = random_ts(True, cfg['day_min'], cfg['day_max'])\n",
    "    flow_id     = f'FLOW_{_layer_flow_counter:05d}'\n",
    "    chain_depth = cfg['chain_length']\n",
    "    _layer_flow_counter += 1\n",
    "    for i in range(cfg['chain_length']):\n",
    "        sender   = chain[i]\n",
    "        receiver = chain[i + 1]\n",
    "        cust     = acc_meta_fraud.loc[sender, 'customer_id']\n",
    "        device   = account_device_map[sender]\n",
    "        ts       = base_ts + timedelta(\n",
    "                       minutes=random.randint(cfg['hop_min_mins'],\n",
    "                                             cfg['hop_max_mins']) * (i + 1))\n",
    "        amt = np.random.lognormal(\n",
    "            cfg['amount_mean_base'] - i * cfg['amount_mean_decay'],\n",
    "            cfg['amount_sigma'])\n",
    "        ch = random.choice(cfg['channels'])\n",
    "        fraud_rows.append(build_row(\n",
    "            txn_id, cust, sender, device, ts, amt, ch, 'layering', 1,\n",
    "            receiver_account_id=receiver,\n",
    "            synthetic_flow_id=flow_id, flow_depth=chain_depth,\n",
    "            hop_number=i + 1, time_since_origin_ts=base_ts,\n",
    "        ))\n",
    "        txn_id += 1\n",
    "\n",
    "_ly_count = sum(1 for r in fraud_rows if r[_FRAUD_TYPE_IDX] == 'layering')\n",
    "print(f'  Layering chains     : {_ly_count:>6,} rows')\n",
    "\n",
    "# â”€â”€ 6C: ACCOUNT TAKEOVER (ATO) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cfg = FRAUD_VOLUMES['ATO']\n",
    "for _ in range(cfg['count']):\n",
    "    acc       = random.choice(active_pool)\n",
    "    cust      = acc_meta_fraud.loc[acc, 'customer_id']\n",
    "    new_dev   = random.choice(all_devs)\n",
    "    exit_bene = random.choice(high_risk_bene_pool)\n",
    "    ts        = random_ts(True, cfg['day_min'], cfg['day_max'])\n",
    "    amt       = np.random.lognormal(cfg['amount_mean'], cfg['amount_sigma'])\n",
    "    ch        = random.choice(cfg['channels'])\n",
    "    fraud_rows.append(build_row(txn_id, cust, acc, new_dev, ts, amt, ch, 'ATO', 1,\n",
    "                                beneficiary_id=exit_bene))\n",
    "    txn_id += 1\n",
    "\n",
    "_ato_count = sum(1 for r in fraud_rows if r[_FRAUD_TYPE_IDX] == 'ATO')\n",
    "print(f'  ATO                 : {_ato_count:>6,} rows')\n",
    "\n",
    "# â”€â”€ 6D: SMURFING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cfg = FRAUD_VOLUMES['smurfing']\n",
    "for _ in range(cfg['num_groups']):\n",
    "    acc       = random.choice(active_pool)\n",
    "    cust      = acc_meta_fraud.loc[acc, 'customer_id']\n",
    "    device    = account_device_map[acc]\n",
    "    exit_bene = random.choice(high_risk_bene_pool)\n",
    "    base_day  = random.randint(0, DATE_RANGE_DAYS - cfg['day_window'] - 1)\n",
    "    for _ in range(random.randint(cfg['min_txns'], cfg['max_txns'])):\n",
    "        ts  = random_ts(True, day_min=base_day, day_max=base_day + cfg['day_window'])\n",
    "        amt = round(random.uniform(cfg['amount_min'], cfg['amount_max']), 2)\n",
    "        ch  = random.choice(cfg['channels'])\n",
    "        fraud_rows.append(build_row(txn_id, cust, acc, device, ts, amt, ch, 'smurfing', 1,\n",
    "                                    beneficiary_id=exit_bene, force_cash=True))\n",
    "        txn_id += 1\n",
    "\n",
    "_sm_count = sum(1 for r in fraud_rows if r[_FRAUD_TYPE_IDX] == 'smurfing')\n",
    "print(f'  Smurfing            : {_sm_count:>6,} rows')\n",
    "\n",
    "# â”€â”€ 6E: IDENTITY FRAUD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cfg      = FRAUD_VOLUMES['identity_fraud']\n",
    "new_accs = accounts.loc[\n",
    "    (accounts['account_open_days'] < cfg['max_account_days']) &\n",
    "    (~accounts['account_id'].isin(inactive_account_set)),\n",
    "    'account_id'\n",
    "].tolist()\n",
    "sample_n = min(cfg['count'], len(new_accs))\n",
    "for acc in random.sample(new_accs, sample_n):\n",
    "    cust      = acc_meta_fraud.loc[acc, 'customer_id']\n",
    "    device    = account_device_map[acc]\n",
    "    exit_bene = random.choice(high_risk_bene_pool)\n",
    "    ts        = random_ts(True, cfg['day_min'], cfg['day_max'])\n",
    "    amt       = np.random.lognormal(cfg['amount_mean'], cfg['amount_sigma'])\n",
    "    ch        = random.choice(cfg['channels'])\n",
    "    fraud_rows.append(build_row(txn_id, cust, acc, device, ts, amt, ch, 'identity_fraud', 1,\n",
    "                                beneficiary_id=exit_bene))\n",
    "    txn_id += 1\n",
    "\n",
    "_id_count = sum(1 for r in fraud_rows if r[_FRAUD_TYPE_IDX] == 'identity_fraud')\n",
    "print(f'  Identity fraud      : {_id_count:>6,} rows')\n",
    "\n",
    "# â”€â”€ 6F: DORMANT-ACCOUNT FRAUD VARIANTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "dormant_accs_list = list(dormant_account_set)\n",
    "\n",
    "# 6F-i  Dormant ATO\n",
    "cfg   = FRAUD_VOLUMES['dormant_ATO']\n",
    "n_ato = max(1, int(len(dormant_accs_list) * cfg['frac_dormant_targeted']))\n",
    "for acc in random.sample(dormant_accs_list, n_ato):\n",
    "    cust       = acc_meta_fraud.loc[acc, 'customer_id']\n",
    "    home_dev   = account_device_map[acc]\n",
    "    other_devs = [d for d in all_devs if d != home_dev]\n",
    "    new_dev    = random.choice(other_devs)\n",
    "    exit_bene  = random.choice(high_risk_bene_pool)\n",
    "    base_day   = random.randint(DORMANT_SECOND_WINDOW[0], DORMANT_SECOND_WINDOW[1] - 1)\n",
    "    for _ in range(random.randint(*cfg['txns_per_account'])):\n",
    "        ts  = random_ts(True, day_min=base_day,\n",
    "                        day_max=min(base_day + 1, DORMANT_SECOND_WINDOW[1]))\n",
    "        amt = np.random.lognormal(cfg['amount_mean'], cfg['amount_sigma'])\n",
    "        ch  = random.choice(cfg['channels'])\n",
    "        fraud_rows.append(build_row(txn_id, cust, acc, new_dev, ts, amt, ch,\n",
    "                                    'dormant_ATO', 1, beneficiary_id=exit_bene))\n",
    "        txn_id += 1\n",
    "\n",
    "_dato_count = sum(1 for r in fraud_rows if r[_FRAUD_TYPE_IDX] == 'dormant_ATO')\n",
    "print(f'  Dormant ATO         : {_dato_count:>6,} rows  ({n_ato} accounts)')\n",
    "\n",
    "# 6F-ii  Dormant smurfing\n",
    "cfg     = FRAUD_VOLUMES['dormant_smurfing']\n",
    "n_smurf = max(1, int(len(dormant_accs_list) * cfg['frac_dormant_targeted']))\n",
    "for acc in random.sample(dormant_accs_list, n_smurf):\n",
    "    cust      = acc_meta_fraud.loc[acc, 'customer_id']\n",
    "    device    = account_device_map[acc]\n",
    "    exit_bene = random.choice(high_risk_bene_pool)\n",
    "    base_day  = random.randint(DORMANT_SECOND_WINDOW[0],\n",
    "                               DORMANT_SECOND_WINDOW[1] - cfg['day_window'] - 1)\n",
    "    for _ in range(random.randint(cfg['min_txns'], cfg['max_txns'])):\n",
    "        ts  = random_ts(True, day_min=base_day, day_max=base_day + cfg['day_window'])\n",
    "        amt = round(random.uniform(cfg['amount_min'], cfg['amount_max']), 2)\n",
    "        ch  = random.choice(cfg['channels'])\n",
    "        fraud_rows.append(build_row(txn_id, cust, acc, device, ts, amt, ch,\n",
    "                                    'dormant_smurfing', 1,\n",
    "                                    beneficiary_id=exit_bene, force_cash=True))\n",
    "        txn_id += 1\n",
    "\n",
    "_dsm_count = sum(1 for r in fraud_rows if r[_FRAUD_TYPE_IDX] == 'dormant_smurfing')\n",
    "print(f'  Dormant smurfing    : {_dsm_count:>6,} rows  ({n_smurf} accounts)')\n",
    "\n",
    "# 6F-iii  Dormant-to-offshore\n",
    "cfg        = FRAUD_VOLUMES['dormant_to_offshore']\n",
    "n_offshore = max(1, int(len(dormant_accs_list) * cfg['frac_dormant_targeted']))\n",
    "exit_pool  = offshore_crypto_pool if offshore_crypto_pool else high_risk_bene_pool\n",
    "for acc in random.sample(dormant_accs_list, n_offshore):\n",
    "    cust     = acc_meta_fraud.loc[acc, 'customer_id']\n",
    "    device   = account_device_map[acc]\n",
    "    base_day = random.randint(DORMANT_SECOND_WINDOW[0], DORMANT_SECOND_WINDOW[1] - 2)\n",
    "    for _ in range(random.randint(*cfg['txns_per_account'])):\n",
    "        exit_bene = random.choice(exit_pool)\n",
    "        ts  = random_ts(True, day_min=base_day,\n",
    "                        day_max=min(base_day + 2, DORMANT_SECOND_WINDOW[1]))\n",
    "        amt = np.random.lognormal(cfg['amount_mean'], cfg['amount_sigma'])\n",
    "        ch  = random.choice(cfg['channels'])\n",
    "        fraud_rows.append(build_row(txn_id, cust, acc, device, ts, amt, ch,\n",
    "                                    'dormant_to_offshore', 1,\n",
    "                                    beneficiary_id=exit_bene))\n",
    "        txn_id += 1\n",
    "\n",
    "_doff_count = sum(1 for r in fraud_rows if r[_FRAUD_TYPE_IDX] == 'dormant_to_offshore')\n",
    "print(f'  Dormantâ†’offshore    : {_doff_count:>6,} rows  ({n_offshore} accounts)')\n",
    "\n",
    "fraud_df_active = pd.DataFrame(fraud_rows, columns=TXN_COLS)\n",
    "\n",
    "# â”€â”€ Assertions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "assert fraud_df_active['fraud_type'].nunique() == 8, 'Expected exactly 8 active fraud typologies'\n",
    "smurf_mask = fraud_df_active['fraud_type'].isin({'smurfing','dormant_smurfing'})\n",
    "assert fraud_df_active.loc[smurf_mask, 'cash_flag'].eq(1).all(), 'Smurfing cash_flag must be 1'\n",
    "assert not fraud_df_active['sender_account_id'].isin(inactive_account_set).any(), \\\n",
    "    'âŒ Active-fraud pool must not include inactive accounts'\n",
    "\n",
    "print(f'\\nâœ… Active/Dormant fraud complete : {len(fraud_df_active):,} rows across 8 typologies')\n",
    "fraud_df_active['fraud_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "id": "A7_inactive",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# â”€â”€ A-7: Inactive-User Typologies (NEW) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#\n",
    "# Each inactive account has a precisely tracked Â«last_pre_silence_tsÂ» which\n",
    "# is the latest timestamp from its early cluster (Phase 1).\n",
    "#\n",
    "# All reactivation transactions begin on day â‰¥ INACTIVE_REACT_START, which\n",
    "# is INACTIVE_EARLY_END + INACTIVE_GAP_DAYS, guaranteeing the 45-day gap.\n",
    "#\n",
    "# no_of_inactive_days (computed in Cell A-8) =\n",
    "#     (reactivation_txn.timestamp.date âˆ’ last_pre_silence_ts.date).days\n",
    "# â†’ always â‰¥ INACTIVE_GAP_DAYS (45) for reactivation rows\n",
    "# â†’ 0  for early-cluster rows (still in active phase)\n",
    "# â†’ NaN for all non-inactive accounts\n",
    "\n",
    "# â”€â”€ Shuffle & partition inactive pool into 4 mutually exclusive subsets â”€â”€â”€â”€â”€â”€â”€\n",
    "inactive_list = list(inactive_account_set)\n",
    "random.shuffle(inactive_list)\n",
    "n_inact = len(inactive_list)\n",
    "\n",
    "n_iato   = max(1, int(n_inact * INACTIVE_FRAUD_FRACS['inactive_ATO']))\n",
    "n_ism    = max(1, int(n_inact * INACTIVE_FRAUD_FRACS['inactive_smurfing']))\n",
    "n_ioff   = max(1, int(n_inact * INACTIVE_FRAUD_FRACS['inactive_to_offshore']))\n",
    "n_ilegit = n_inact - n_iato - n_ism - n_ioff   # remainder â†’ clean reactivation\n",
    "\n",
    "subset_ato      = inactive_list[:n_iato]\n",
    "subset_smurf    = inactive_list[n_iato : n_iato + n_ism]\n",
    "subset_offshore = inactive_list[n_iato + n_ism : n_iato + n_ism + n_ioff]\n",
    "subset_legit    = inactive_list[n_iato + n_ism + n_ioff :]\n",
    "\n",
    "print(f'Inactive pool ({n_inact} accounts) â€” sub-pattern allocation:')\n",
    "print(f'   inactive_ATO          : {len(subset_ato):>5}  ({len(subset_ato)/n_inact*100:.0f}%)')\n",
    "print(f'   inactive_smurfing     : {len(subset_smurf):>5}  ({len(subset_smurf)/n_inact*100:.0f}%)')\n",
    "print(f'   inactive_to_offshore  : {len(subset_offshore):>5}  ({len(subset_offshore)/n_inact*100:.0f}%)')\n",
    "print(f'   inactive_legit (clean): {len(subset_legit):>5}  ({len(subset_legit)/n_inact*100:.0f}%)')\n",
    "print()\n",
    "\n",
    "# â”€â”€ Record each account's last pre-silence timestamp â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# We approximate it as the latest possible early-cluster day minus a small jitter.\n",
    "inactive_last_ts_map: dict = {}\n",
    "for acc in inactive_list:\n",
    "    end_day = INACTIVE_EARLY_END - random.randint(0, 3)   # 0â€“3 days before window end\n",
    "    inactive_last_ts_map[acc] = START_DATE + timedelta(\n",
    "        days    = max(0, end_day),\n",
    "        hours   = weighted_hour(fraud=False),\n",
    "        minutes = random.randint(0, 59),\n",
    "    )\n",
    "\n",
    "inactive_rows: list = []\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 7A: inactive_ATO\n",
    "#     Account taken over by adversary after 45+ day silence.\n",
    "#     Signals: foreign device, off-hours, large amounts, high-risk bene.\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cfg = FRAUD_VOLUMES['inactive_ATO']\n",
    "for acc in subset_ato:\n",
    "    cust      = acc_meta_fraud.loc[acc, 'customer_id']\n",
    "    home_dev  = account_device_map[acc]\n",
    "    other_dev = random.choice([d for d in all_devs if d != home_dev])\n",
    "    exit_bene = random.choice(high_risk_bene_pool)\n",
    "    for _ in range(random.randint(*cfg['txns_per_account'])):\n",
    "        ts  = random_ts(fraud=True,\n",
    "                        day_min=INACTIVE_REACT_START,\n",
    "                        day_max=DATE_RANGE_DAYS)\n",
    "        amt = np.random.lognormal(cfg['amount_mean'], cfg['amount_sigma'])\n",
    "        ch  = random.choice(cfg['channels'])\n",
    "        inactive_rows.append(build_row(\n",
    "            txn_id, cust, acc, other_dev, ts, amt, ch, 'inactive_ATO', 1,\n",
    "            beneficiary_id=exit_bene))\n",
    "        txn_id += 1\n",
    "\n",
    "_iato = sum(1 for r in inactive_rows if r[_FRAUD_TYPE_IDX] == 'inactive_ATO')\n",
    "print(f'  inactive_ATO          : {_iato:>6,} rows')\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 7B: inactive_smurfing\n",
    "#     Burst of cash transactions just below â‚¹10k reporting threshold\n",
    "#     within a 1â€“3 day window after the silence period ends.\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cfg = FRAUD_VOLUMES['inactive_smurfing']\n",
    "for acc in subset_smurf:\n",
    "    cust      = acc_meta_fraud.loc[acc, 'customer_id']\n",
    "    device    = account_device_map[acc]     # own device (account re-used after takeover)\n",
    "    exit_bene = random.choice(high_risk_bene_pool)\n",
    "    base_day  = random.randint(\n",
    "        INACTIVE_REACT_START,\n",
    "        max(INACTIVE_REACT_START, DATE_RANGE_DAYS - cfg['day_window'] - 1)\n",
    "    )\n",
    "    for _ in range(random.randint(cfg['min_txns'], cfg['max_txns'])):\n",
    "        ts  = random_ts(fraud=True, day_min=base_day,\n",
    "                        day_max=min(base_day + cfg['day_window'], DATE_RANGE_DAYS))\n",
    "        amt = round(random.uniform(cfg['amount_min'], cfg['amount_max']), 2)\n",
    "        ch  = random.choice(cfg['channels'])\n",
    "        inactive_rows.append(build_row(\n",
    "            txn_id, cust, acc, device, ts, amt, ch, 'inactive_smurfing', 1,\n",
    "            beneficiary_id=exit_bene, force_cash=True))\n",
    "        txn_id += 1\n",
    "\n",
    "_ism = sum(1 for r in inactive_rows if r[_FRAUD_TYPE_IDX] == 'inactive_smurfing')\n",
    "print(f'  inactive_smurfing     : {_ism:>6,} rows')\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 7C: inactive_to_offshore\n",
    "#     Reactivated account immediately wires to crypto / offshore destination.\n",
    "#     Signal: very large single transaction, high-risk beneficiary, web/mobile.\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cfg       = FRAUD_VOLUMES['inactive_to_offshore']\n",
    "exit_pool = offshore_crypto_pool if offshore_crypto_pool else high_risk_bene_pool\n",
    "for acc in subset_offshore:\n",
    "    cust     = acc_meta_fraud.loc[acc, 'customer_id']\n",
    "    device   = account_device_map[acc]\n",
    "    base_day = random.randint(\n",
    "        INACTIVE_REACT_START,\n",
    "        max(INACTIVE_REACT_START, DATE_RANGE_DAYS - 3)\n",
    "    )\n",
    "    for _ in range(random.randint(*cfg['txns_per_account'])):\n",
    "        exit_bene = random.choice(exit_pool)\n",
    "        ts  = random_ts(fraud=True, day_min=base_day,\n",
    "                        day_max=min(base_day + 2, DATE_RANGE_DAYS))\n",
    "        amt = np.random.lognormal(cfg['amount_mean'], cfg['amount_sigma'])\n",
    "        ch  = random.choice(cfg['channels'])\n",
    "        inactive_rows.append(build_row(\n",
    "            txn_id, cust, acc, device, ts, amt, ch, 'inactive_to_offshore', 1,\n",
    "            beneficiary_id=exit_bene))\n",
    "        txn_id += 1\n",
    "\n",
    "_ioff = sum(1 for r in inactive_rows if r[_FRAUD_TYPE_IDX] == 'inactive_to_offshore')\n",
    "print(f'  inactive_to_offshore  : {_ioff:>6,} rows')\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 7D: inactive_legit  â€” clean reactivation (label=0)\n",
    "#     Normal-sized amounts on the account's own home device.\n",
    "#     Still carries no_of_inactive_days so AML analysts can study\n",
    "#     benign reactivation patterns vs. fraudulent ones.\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for acc in subset_legit:\n",
    "    kyc    = acc_meta_fraud.loc[acc, 'kyc_level']\n",
    "    cust   = acc_meta_fraud.loc[acc, 'customer_id']\n",
    "    device = account_device_map[acc]\n",
    "    params = AMOUNT_BY_KYC.get(str(kyc).lower(), AMOUNT_DEFAULT)\n",
    "    react_day = random.randint(INACTIVE_REACT_START, DATE_RANGE_DAYS)\n",
    "    for _ in range(random.randint(2, 6)):\n",
    "        ts  = random_ts(fraud=False, day_min=react_day,\n",
    "                        day_max=min(react_day + 5, DATE_RANGE_DAYS))\n",
    "        amt = np.random.lognormal(params['mean'], params['sigma'])\n",
    "        ch  = random.choices(CHANNELS, weights=CHANNEL_PROBS)[0]\n",
    "        if random.random() < INTERNAL_TRANSFER_PROB:\n",
    "            inactive_rows.append(build_row(\n",
    "                txn_id, cust, acc, device, ts, amt, ch, 'normal', 0,\n",
    "                receiver_account_id=random.choice(all_account_ids)))\n",
    "        else:\n",
    "            inactive_rows.append(build_row(\n",
    "                txn_id, cust, acc, device, ts, amt, ch, 'normal', 0,\n",
    "                beneficiary_id=random.choice(account_beneficiaries_map[acc])))\n",
    "        txn_id += 1\n",
    "\n",
    "inactive_df = pd.DataFrame(inactive_rows, columns=TXN_COLS)\n",
    "_ilegit = int((inactive_df['label'] == 0).sum())\n",
    "print(f'  inactive_legit (clean): {_ilegit:>6,} rows')\n",
    "\n",
    "# â”€â”€ Assertions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "assert inactive_df['sender_account_id'].isin(inactive_account_set).all(), \\\n",
    "    'âŒ Inactive rows must only come from inactive accounts'\n",
    "ism_mask_df = inactive_df['fraud_type'] == 'inactive_smurfing'\n",
    "if ism_mask_df.any():\n",
    "    assert inactive_df.loc[ism_mask_df, 'cash_flag'].eq(1).all(), \\\n",
    "        'âŒ inactive_smurfing cash_flag must be 1'\n",
    "\n",
    "print(f'\\nâœ… Inactive typologies complete : {len(inactive_df):,} rows  '\n",
    "      f'(fraud rate {inactive_df[\"label\"].mean()*100:.1f}%)')\n",
    "inactive_df['fraud_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "id": "A8_merge_stamp",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# â”€â”€ A-8: Merge, Stamp no_of_inactive_days, Rebalance & FK-Enrichment â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 8a: Stack all three DataFrames â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "combined = pd.concat([legit_df, fraud_df_active, inactive_df], ignore_index=True)\n",
    "combined['timestamp'] = pd.to_datetime(combined['timestamp'])\n",
    "\n",
    "# 8b: Stamp no_of_inactive_days â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#\n",
    "# Column semantics:\n",
    "#   NaN   â€” sender_account_id is NOT in inactive_account_set\n",
    "#   0     â€” inactive account, but this row is in the PRE-SILENCE early cluster\n",
    "#           (timestamp â‰¤ INACTIVE_EARLY_END)\n",
    "#   â‰¥ 45  â€” reactivation row; value = exact calendar-day gap since last\n",
    "#           pre-silence transaction (always â‰¥ INACTIVE_GAP_DAYS)\n",
    "\n",
    "combined['no_of_inactive_days'] = np.nan\n",
    "\n",
    "inact_mask = combined['sender_account_id'].isin(inactive_account_set)\n",
    "\n",
    "def _compute_inactive_days(row):\n",
    "    last_ts = inactive_last_ts_map.get(row['sender_account_id'])\n",
    "    if last_ts is None:\n",
    "        return np.nan\n",
    "    delta = (row['timestamp'].date() - last_ts.date()).days\n",
    "    if delta < INACTIVE_GAP_DAYS:\n",
    "        # Row is in the early active phase â€” not a reactivation yet\n",
    "        return 0\n",
    "    return int(delta)\n",
    "\n",
    "combined.loc[inact_mask, 'no_of_inactive_days'] = (\n",
    "    combined.loc[inact_mask].apply(_compute_inactive_days, axis=1)\n",
    ")\n",
    "\n",
    "# Quick sanity check\n",
    "react_check = combined[\n",
    "    inact_mask & (combined['no_of_inactive_days'] >= INACTIVE_GAP_DAYS)\n",
    "]\n",
    "print(f'Inactive reactivation rows (no_of_inactive_days â‰¥ {INACTIVE_GAP_DAYS}): '\n",
    "      f'{len(react_check):,}')\n",
    "print(f'  gap range : {react_check[\"no_of_inactive_days\"].min():.0f} â€“ '\n",
    "      f'{react_check[\"no_of_inactive_days\"].max():.0f} days')\n",
    "print(f'  mean gap  : {react_check[\"no_of_inactive_days\"].mean():.1f} days')\n",
    "print()\n",
    "\n",
    "# 8c: Rebalance to TARGET_FRAUD_RATE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "current_fraud = int(combined['label'].sum())\n",
    "current_total = len(combined)\n",
    "current_rate  = current_fraud / current_total\n",
    "print(f'Pre-rebalance  : {current_rate:.4f} fraud rate ({current_fraud:,} / {current_total:,})')\n",
    "\n",
    "# Oversample pool = ALL fraud rows (active + inactive)\n",
    "all_fraud_df = pd.concat([\n",
    "    fraud_df_active,\n",
    "    inactive_df[inactive_df['label'] == 1]\n",
    "], ignore_index=True)\n",
    "\n",
    "if current_rate < TARGET_FRAUD_RATE:\n",
    "    needed = int(TARGET_FRAUD_RATE * current_total / (1 - TARGET_FRAUD_RATE)) - current_fraud\n",
    "    extra  = all_fraud_df.sample(n=needed, replace=True, random_state=42).copy()\n",
    "    extra['transaction_id'] = [f'T{txn_id + i}_OS' for i in range(len(extra))]\n",
    "    combined = pd.concat([combined, extra], ignore_index=True)\n",
    "    combined['timestamp'] = pd.to_datetime(combined['timestamp'])\n",
    "    print(f'Oversampled    : +{needed:,} fraud rows â†’ target {TARGET_FRAUD_RATE:.0%}')\n",
    "\n",
    "raw_txns = combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f'Post-rebalance : {raw_txns[\"label\"].mean():.4f} fraud rate '\n",
    "      f'({int(raw_txns[\"label\"].sum()):,} / {len(raw_txns):,})')\n",
    "\n",
    "# 8d: FK joins â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "txns = raw_txns.copy()\n",
    "\n",
    "acc_join_cols = [\n",
    "    'account_id', 'avg_balance', 'account_open_days',\n",
    "    'kyc_level', 'country_risk', 'income_bracket',\n",
    "    'customer_risk_rating', 'pep_flag', 'occupation',\n",
    "    'industry', 'account_type',\n",
    "    'home_lat', 'home_lon', 'home_city',\n",
    "    'shared_kyc_id', 'shared_phone_hash', 'shared_email_hash',\n",
    "]\n",
    "txns = txns.merge(\n",
    "    accounts[acc_join_cols].rename(columns={'account_id': 'sender_account_id'}),\n",
    "    on='sender_account_id', how='left'\n",
    ")\n",
    "dev_cols  = ['device_id', 'device_age_days', 'rooted_flag', 'os_type',\n",
    "             'vpn_flag', 'emulator_flag']\n",
    "txns = txns.merge(devices[dev_cols], on='device_id', how='left')\n",
    "\n",
    "bene_cols = ['beneficiary_id', 'beneficiary_type', 'beneficiary_country_risk']\n",
    "txns = txns.merge(beneficiaries[bene_cols], on='beneficiary_id', how='left')\n",
    "\n",
    "print(f'\\nâœ… Merge + enrichment complete : {len(txns):,} rows Ã— {txns.shape[1]} cols')\n",
    "print(f'   account join      : +{len(acc_join_cols)-1} cols')\n",
    "print(f'   device join       : +{len(dev_cols)-1} cols')\n",
    "print(f'   bene join         : +{len(bene_cols)-1} cols')\n",
    "print(f'   no_of_inactive_days  non-NaN : {txns[\"no_of_inactive_days\"].notna().sum():,}')"
   ]
  },
  {
   "cell_type": "code",
   "id": "A9_ip",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# â”€â”€ A-9: IP Graph Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Enhancement for inactive typologies:\n",
    "#   inactive_ATO rows â†’ always ip_type='risk' (adversary TOR/VPN usage)\n",
    "#   inactive reactivation rows (fraud) â†’ +0.05 ip_risk_score bump\n",
    "\n",
    "print('Computing IP Graph Layer...')\n",
    "\n",
    "ROAM_CITIES = [\n",
    "    (28.6139,77.2090),(19.0760,72.8777),(12.9716,77.5946),(22.5726,88.3639),\n",
    "    (17.3850,78.4867),(13.0827,80.2707),(18.5204,73.8567),(23.0225,72.5714),\n",
    "    (26.9124,75.7873),(21.1702,72.8311),\n",
    "]\n",
    "\n",
    "rng_ip   = np.random.default_rng(RANDOM_SEED + 99)\n",
    "RISK_IPS = [\n",
    "    f'{pfx}.{rng_ip.integers(1,254)}.{rng_ip.integers(1,254)}'\n",
    "    for pfx in HIGH_RISK_IP_PREFIXES for _ in range(20)\n",
    "]\n",
    "\n",
    "def _home_ip(customer_id, account_id):\n",
    "    h = hash(str(customer_id) + str(account_id)) & 0xFFFF\n",
    "    return f'10.{(h >> 8) & 0xFF}.{h & 0xFF}.{hash(str(account_id)) & 0xFF}'\n",
    "\n",
    "rng_geo = np.random.default_rng(RANDOM_SEED + 77)\n",
    "ip_addresses, ip_risk_scores, geo_lats, geo_lons = [], [], [], []\n",
    "\n",
    "for _, row in txns.iterrows():\n",
    "    cid    = row['customer_id']\n",
    "    aid    = row['sender_account_id']\n",
    "    vpn    = int(row.get('vpn_flag',      0) or 0)\n",
    "    rooted = int(row.get('rooted_flag',   0) or 0)\n",
    "    emu    = int(row.get('emulator_flag', 0) or 0)\n",
    "    night  = int(row.get('is_night',      0) or 0)\n",
    "    crisk  = row.get('country_risk', 'low')  or 'low'\n",
    "    kyc    = row.get('kyc_level',  'medium') or 'medium'\n",
    "    ftype  = row.get('fraud_type', '')       or ''\n",
    "    inact_days = row.get('no_of_inactive_days', np.nan)\n",
    "\n",
    "    # inactive_ATO always routed through adversary-controlled risk IPs\n",
    "    if vpn == 1 or ftype == 'inactive_ATO':\n",
    "        ip_type = 'risk'\n",
    "    else:\n",
    "        r = float(rng_geo.random())\n",
    "        ip_type = ('home' if r < IP_HOME_FRAC\n",
    "                   else 'roam' if r < IP_HOME_FRAC + IP_ROAM_FRAC\n",
    "                   else 'risk')\n",
    "\n",
    "    if ip_type == 'home':\n",
    "        ip = _home_ip(cid, aid)\n",
    "    elif ip_type == 'roam':\n",
    "        ip = (f'{int(rng_geo.integers(100,223))}.'\n",
    "              f'{int(rng_geo.integers(0,255))}.'\n",
    "              f'{int(rng_geo.integers(0,255))}.'\n",
    "              f'{int(rng_geo.integers(1,254))}')\n",
    "    else:\n",
    "        ip = RISK_IPS[int(rng_geo.integers(0, len(RISK_IPS)))]\n",
    "    ip_addresses.append(ip)\n",
    "\n",
    "    base  = (IP_HOME_BASE_SCORE if ip_type == 'home'\n",
    "             else IP_ROAM_BASE_SCORE if ip_type == 'roam'\n",
    "             else IP_RISK_BASE_SCORE)\n",
    "    score = base\n",
    "    score += 0.15 if vpn    else 0\n",
    "    score += 0.10 if rooted else 0\n",
    "    score += 0.10 if emu    else 0\n",
    "    score += 0.10 if night  else 0\n",
    "    score += 0.05 if str(crisk).lower() == 'high' else 0\n",
    "    score -= 0.05 if str(kyc).lower()   == 'high' else 0\n",
    "    # Extra bump: inactive fraud reactivation (not clean legit)\n",
    "    if (pd.notna(inact_days) and\n",
    "            inact_days >= INACTIVE_GAP_DAYS and\n",
    "            ftype not in ('normal', '')):\n",
    "        score += 0.05\n",
    "    ip_risk_scores.append(round(min(max(score, 0.0), 1.0), 4))\n",
    "\n",
    "    if ip_type == 'home':\n",
    "        if cust_geo_map is not None and cid in cust_geo_map.index:\n",
    "            hlat = float(cust_geo_map.loc[cid, 'home_lat'])\n",
    "            hlon = float(cust_geo_map.loc[cid, 'home_lon'])\n",
    "        else:\n",
    "            hlat, hlon = 20.5937, 78.9629\n",
    "        geo_lats.append(round(hlat + float(rng_geo.normal(0, 0.05)), 6))\n",
    "        geo_lons.append(round(hlon + float(rng_geo.normal(0, 0.05)), 6))\n",
    "    elif ip_type == 'roam':\n",
    "        city = ROAM_CITIES[int(rng_geo.integers(0, len(ROAM_CITIES)))]\n",
    "        geo_lats.append(round(city[0] + float(rng_geo.normal(0, 0.3)), 6))\n",
    "        geo_lons.append(round(city[1] + float(rng_geo.normal(0, 0.3)), 6))\n",
    "    else:\n",
    "        geo_lats.append(round(float(rng_geo.uniform(-60, 70)), 6))\n",
    "        geo_lons.append(round(float(rng_geo.uniform(-180, 180)), 6))\n",
    "\n",
    "txns['ip_address']    = ip_addresses\n",
    "txns['ip_risk_score'] = ip_risk_scores\n",
    "txns['geo_lat']       = geo_lats\n",
    "txns['geo_lon']       = geo_lons\n",
    "\n",
    "print(f'âœ… IP Graph Layer added: {txns.shape[1]} cols')\n",
    "print(f'   home IPs   (score â‰¤ 0.20): {(txns[\"ip_risk_score\"] <= 0.20).sum():,}')\n",
    "print(f'   roam IPs   (0.20â€“0.69)   : {((txns[\"ip_risk_score\"] > 0.20) & (txns[\"ip_risk_score\"] < 0.70)).sum():,}')\n",
    "print(f'   risk IPs   (score â‰¥ 0.70): {(txns[\"ip_risk_score\"] >= 0.70).sum():,}')"
   ]
  },
  {
   "cell_type": "code",
   "id": "A10_shared_id",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# â”€â”€ A-10: Shared Identity Enrichment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Original typologies: unchanged.\n",
    "# Inactive typologies: distinct prefix tokens to avoid ID collision.\n",
    "\n",
    "def _group_id(prefix, key, n_groups=200):\n",
    "    h = int(hashlib.md5(str(key).encode()).hexdigest(), 16)\n",
    "    return f'{prefix}_{h % n_groups:05d}'\n",
    "\n",
    "fraud_mask = txns['label'] == 1\n",
    "ft         = txns['fraud_type']\n",
    "\n",
    "# â”€â”€ Original 8 typologies (logic UNCHANGED) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "mr_mask = fraud_mask & (ft == 'mule_ring')\n",
    "txns.loc[mr_mask, 'shared_kyc_id'] = (\n",
    "    txns.loc[mr_mask, 'synthetic_flow_id'].apply(lambda fid: _group_id('KYC', fid))\n",
    ")\n",
    "\n",
    "ly_mask = fraud_mask & (ft == 'layering')\n",
    "txns.loc[ly_mask, 'shared_phone_hash'] = (\n",
    "    txns.loc[ly_mask, 'synthetic_flow_id'].apply(lambda fid: _group_id('PHONE', fid))\n",
    ")\n",
    "\n",
    "sm_mask = fraud_mask & (ft == 'smurfing')\n",
    "txns.loc[sm_mask, 'shared_email_hash'] = (\n",
    "    txns.loc[sm_mask, 'sender_account_id'].apply(lambda aid: _group_id('EMAIL', aid))\n",
    ")\n",
    "\n",
    "id_mask = fraud_mask & (ft == 'identity_fraud')\n",
    "txns.loc[id_mask, 'shared_email_hash'] = (\n",
    "    txns.loc[id_mask, 'customer_id'].apply(lambda cid: _group_id('EMAIL', cid, n_groups=50))\n",
    ")\n",
    "txns.loc[id_mask, 'shared_phone_hash'] = (\n",
    "    txns.loc[id_mask, 'customer_id'].apply(lambda cid: _group_id('PHONE', cid, n_groups=50))\n",
    ")\n",
    "\n",
    "ato_mask = fraud_mask & ft.isin({'ATO', 'dormant_ATO'})\n",
    "txns.loc[ato_mask, 'shared_email_hash'] = (\n",
    "    txns.loc[ato_mask, 'sender_account_id'].apply(lambda aid: _group_id('EMAIL', aid, n_groups=300))\n",
    ")\n",
    "\n",
    "dsm_mask = fraud_mask & (ft == 'dormant_smurfing')\n",
    "txns.loc[dsm_mask, 'shared_kyc_id'] = (\n",
    "    txns.loc[dsm_mask, 'sender_account_id'].apply(lambda aid: _group_id('KYC', aid, n_groups=100))\n",
    ")\n",
    "txns.loc[dsm_mask, 'shared_phone_hash'] = (\n",
    "    txns.loc[dsm_mask, 'sender_account_id'].apply(lambda aid: _group_id('PHONE', aid, n_groups=100))\n",
    ")\n",
    "\n",
    "doff_mask = fraud_mask & (ft == 'dormant_to_offshore')\n",
    "txns.loc[doff_mask, 'shared_kyc_id'] = (\n",
    "    txns.loc[doff_mask, 'sender_account_id'].apply(lambda aid: _group_id('KYC', aid, n_groups=50))\n",
    ")\n",
    "\n",
    "# â”€â”€ NEW: Inactive typology shared-identity tokens â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Prefixes are distinct (INACT_*) to avoid confusion with dormant / active pools.\n",
    "\n",
    "# inactive_ATO â†’ shared email (same adversarial takeover infrastructure)\n",
    "iato_mask = fraud_mask & (ft == 'inactive_ATO')\n",
    "txns.loc[iato_mask, 'shared_email_hash'] = (\n",
    "    txns.loc[iato_mask, 'sender_account_id']\n",
    "    .apply(lambda aid: _group_id('INACT_EMAIL_ATO', aid, n_groups=400))\n",
    ")\n",
    "\n",
    "# inactive_smurfing â†’ shared phone + email (same cash-structuring operative)\n",
    "ism_mask = fraud_mask & (ft == 'inactive_smurfing')\n",
    "txns.loc[ism_mask, 'shared_phone_hash'] = (\n",
    "    txns.loc[ism_mask, 'sender_account_id']\n",
    "    .apply(lambda aid: _group_id('INACT_PHONE_SM', aid, n_groups=150))\n",
    ")\n",
    "txns.loc[ism_mask, 'shared_email_hash'] = (\n",
    "    txns.loc[ism_mask, 'sender_account_id']\n",
    "    .apply(lambda aid: _group_id('INACT_EMAIL_SM', aid, n_groups=150))\n",
    ")\n",
    "\n",
    "# inactive_to_offshore â†’ shared KYC + phone (same shell-entity documents)\n",
    "ioff_mask = fraud_mask & (ft == 'inactive_to_offshore')\n",
    "txns.loc[ioff_mask, 'shared_kyc_id'] = (\n",
    "    txns.loc[ioff_mask, 'sender_account_id']\n",
    "    .apply(lambda aid: _group_id('INACT_KYC_OFF', aid, n_groups=75))\n",
    ")\n",
    "txns.loc[ioff_mask, 'shared_phone_hash'] = (\n",
    "    txns.loc[ioff_mask, 'sender_account_id']\n",
    "    .apply(lambda aid: _group_id('INACT_PHONE_OFF', aid, n_groups=75))\n",
    ")\n",
    "\n",
    "print('âœ… Shared Identity Enrichment complete')\n",
    "print(f'   shared_kyc_id      non-null : {txns[\"shared_kyc_id\"].notna().sum():,}')\n",
    "print(f'   shared_phone_hash  non-null : {txns[\"shared_phone_hash\"].notna().sum():,}')\n",
    "print(f'   shared_email_hash  non-null : {txns[\"shared_email_hash\"].notna().sum():,}')\n",
    "print('\\nInactive sub-pattern coverage:')\n",
    "print(f'   inactive_ATO   â†’ email  : {txns.loc[iato_mask, \"shared_email_hash\"].notna().sum():,}')\n",
    "print(f'   inactive_smurf â†’ phone  : {txns.loc[ism_mask,  \"shared_phone_hash\"].notna().sum():,}')\n",
    "print(f'   inactive_offsh â†’ kyc    : {txns.loc[ioff_mask, \"shared_kyc_id\"].notna().sum():,}')"
   ]
  },
  {
   "cell_type": "code",
   "id": "A11_validate",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# â”€â”€ A-11: Validation Dashboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "SEP = '=' * 68\n",
    "sep = 'â”€' * 68\n",
    "\n",
    "print(SEP)\n",
    "print('DATASET VALIDATION REPORT')\n",
    "print(SEP)\n",
    "\n",
    "total_rows   = len(txns)\n",
    "fraud_n      = int(txns['label'].sum())\n",
    "legit_n      = total_rows - fraud_n\n",
    "\n",
    "print(f'  Total rows             : {total_rows:>10,}')\n",
    "print(f'  Fraud rows (label=1)   : {fraud_n:>10,}  ({fraud_n/total_rows*100:.2f}%)')\n",
    "print(f'  Legit rows (label=0)   : {legit_n:>10,}  ({legit_n/total_rows*100:.2f}%)')\n",
    "print(f'  Total columns          : {txns.shape[1]:>10}')\n",
    "print()\n",
    "\n",
    "print(sep)\n",
    "print('TYPOLOGY BREAKDOWN')\n",
    "print(sep)\n",
    "tvc = txns['fraud_type'].value_counts(dropna=False)\n",
    "for typ, cnt in tvc.items():\n",
    "    pct  = cnt / total_rows * 100\n",
    "    pool = ('  â† INACTIVE' if str(typ).startswith('inactive_')\n",
    "            else '  â† DORMANT' if str(typ).startswith('dormant_')\n",
    "            else '')\n",
    "    print(f'  {str(typ):<30}  {cnt:>8,}  ({pct:5.2f}%){pool}')\n",
    "print()\n",
    "\n",
    "print(sep)\n",
    "print('INACTIVE ACCOUNT STATISTICS')\n",
    "print(sep)\n",
    "inact_txns = txns[txns['sender_account_id'].isin(inactive_account_set)]\n",
    "react_txns = inact_txns[inact_txns['no_of_inactive_days'] >= INACTIVE_GAP_DAYS]\n",
    "early_txns = inact_txns[inact_txns['no_of_inactive_days'] == 0]\n",
    "\n",
    "print(f'  Inactive accounts sampled   : {len(inactive_account_set):,} '\n",
    "      f'({len(inactive_account_set)/len(all_account_ids)*100:.1f}% of all accounts)')\n",
    "print(f'  Total rows from inactive    : {len(inact_txns):,}')\n",
    "print(f'    Pre-silence early rows    : {len(early_txns):,}  (no_of_inactive_days = 0)')\n",
    "print(f'    Reactivation rows (â‰¥45d)  : {len(react_txns):,}')\n",
    "print(f'      Fraud reactivation      : {int(react_txns[\"label\"].sum()):,}')\n",
    "print(f'      Legit reactivation      : {int((react_txns[\"label\"]==0).sum()):,}')\n",
    "if len(react_txns):\n",
    "    print(f'  no_of_inactive_days stats   :')\n",
    "    print(f'    min    = {react_txns[\"no_of_inactive_days\"].min():.0f} days')\n",
    "    print(f'    median = {react_txns[\"no_of_inactive_days\"].median():.0f} days')\n",
    "    print(f'    mean   = {react_txns[\"no_of_inactive_days\"].mean():.1f} days')\n",
    "    print(f'    max    = {react_txns[\"no_of_inactive_days\"].max():.0f} days')\n",
    "print()\n",
    "\n",
    "print(sep)\n",
    "print('OVERLAP & INTEGRITY CHECKS')\n",
    "print(sep)\n",
    "overlap = dormant_account_set & inactive_account_set\n",
    "print(f'  dormant âˆ© inactive          : {len(overlap)}  '\n",
    "      f'â†’ {\"âœ… CLEAN\" if not overlap else \"âŒ OVERLAP\"}')\n",
    "cross = fraud_df_active['sender_account_id'].isin(inactive_account_set).sum()\n",
    "print(f'  Active-fraud rows in inact  : {cross}  '\n",
    "      f'â†’ {\"âœ… CLEAN\" if cross == 0 else \"âŒ OVERLAP\"}')\n",
    "inact_in_active = inactive_df['sender_account_id'].isin(dormant_account_set).sum()\n",
    "print(f'  Inactive rows in dormant    : {inact_in_active}  '\n",
    "      f'â†’ {\"âœ… CLEAN\" if inact_in_active == 0 else \"âŒ OVERLAP\"}')\n",
    "print()\n",
    "\n",
    "print(sep)\n",
    "print('no_of_inactive_days COLUMN SUMMARY')\n",
    "print(sep)\n",
    "print(f'  dtype   : {txns[\"no_of_inactive_days\"].dtype}')\n",
    "print(f'  NaN     : {txns[\"no_of_inactive_days\"].isna().sum():,}  '\n",
    "      f'(non-inactive accounts)')\n",
    "print(f'  = 0     : {(txns[\"no_of_inactive_days\"]==0).sum():,}  '\n",
    "      f'(inactive acct early-cluster rows)')\n",
    "print(f'  â‰¥ 45    : {(txns[\"no_of_inactive_days\"]>=INACTIVE_GAP_DAYS).sum():,}  '\n",
    "      f'(reactivation rows)')\n",
    "print(SEP)\n",
    "\n",
    "# Sample of reactivation rows\n",
    "txns[['sender_account_id','timestamp','fraud_type','label','no_of_inactive_days']]\\\n",
    "    .query('no_of_inactive_days >= 45')\\\n",
    "    .sort_values('no_of_inactive_days', ascending=False)\\\n",
    "    .head(12)"
   ]
  },
  {
   "cell_type": "code",
   "id": "A12_save",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# â”€â”€ A-12: Save Stage-1 Output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "txns.to_parquet(OUTPUT_DIR / 'txns_stage1.parquet', index=False)\n",
    "\n",
    "# Dormant set (for Notebook 2b â€” original contract)\n",
    "pd.DataFrame({'account_id': sorted(dormant_account_set)}).to_csv(\n",
    "    OUTPUT_DIR / 'dormant_account_set.csv', index=False\n",
    ")\n",
    "\n",
    "# Inactive set (NEW â€” for Notebook 2b rolling-feature context)\n",
    "pd.DataFrame({\n",
    "    'account_id'    : sorted(inactive_account_set),\n",
    "    'last_active_ts': [\n",
    "        inactive_last_ts_map[a].isoformat()\n",
    "        for a in sorted(inactive_account_set)\n",
    "    ],\n",
    "    'inactive_gap_days': INACTIVE_GAP_DAYS,\n",
    "    'react_start_day'  : INACTIVE_REACT_START,\n",
    "}).to_csv(OUTPUT_DIR / 'inactive_account_set.csv', index=False)\n",
    "\n",
    "size_mb = (OUTPUT_DIR / 'txns_stage1.parquet').stat().st_size / 1024**2\n",
    "\n",
    "print('âœ… All outputs saved')\n",
    "print(f'   txns_stage1.parquet        â†’ {len(txns):,} rows Ã— {txns.shape[1]} cols | {size_mb:.1f} MB')\n",
    "print(f'   dormant_account_set.csv    â†’ {len(dormant_account_set):,} accounts')\n",
    "print(f'   inactive_account_set.csv   â†’ {len(inactive_account_set):,} accounts')\n",
    "print()\n",
    "print('Final column list:')\n",
    "for c in txns.columns:\n",
    "    tag = '  â† NEW' if c == 'no_of_inactive_days' else ''\n",
    "    print(f'   {c}{tag}')\n",
    "print()\n",
    "print('Next step â†’ Run  02b_rolling_features.ipynb')"
   ]
  }
 ]
}
